{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import some usefull libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "import shutil as shutil\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our data and display target names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'spam']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = load_files('data/Enron_1/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "data1['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split our data into train-test set with proportion of 80-20. In order to do that, we're using ${\\it train\\_test\\_split}$ method, from sklearn.\n",
    "\n",
    "First of all, we convert our data to pandas dataframe, so this way it's easier to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2937\n",
      "1    1200\n",
      "Name: spam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'text': data1['data'], 'spam': data1['target']})\n",
    "\n",
    "N_data = len(df1)\n",
    "N_train_data = int(0.8 * N_data); N_test_data = N_data - N_train_data\n",
    "\n",
    "train_data, test_data = train_test_split(df1, train_size=N_train_data, test_size=N_test_data)\n",
    "\n",
    "print(df1.spam.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we take first 5 rows of train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: how to confidently attract , meet and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : cilco storage\\r\\nyes , they are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: stockalert : investors need to know\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: alternative work schedule status\\r\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: guaranteed satisfaction , cheapest pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "1750     1  Subject: how to confidently attract , meet and...\n",
       "949      0  Subject: re : cilco storage\\r\\nyes , they are ...\n",
       "1404     1  Subject: stockalert : investors need to know\\r...\n",
       "3888     0  Subject: alternative work schedule status\\r\\na...\n",
       "1101     1  Subject: guaranteed satisfaction , cheapest pr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use ${\\it CountVectorizer}$ method from sklearn in order to convert the collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "spam_features = vectorizer.fit_transform(train_data.text)\n",
    "\n",
    "print(spam_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting vocabulary has a shape of: (3309, 38225) and its lenght is: 38225\n"
     ]
    }
   ],
   "source": [
    "shape = spam_features.shape\n",
    "print('The resulting vocabulary has a shape of:', shape, 'and its lenght is:', shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of methods of vectorizer function, we can see how many times does ${\\it please}$ appear in the mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27430"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_['please']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply multinomial Naive Bayes in order to classify our dataset. We're using ${\\it MultinomialNB}$ method from sklearn. Finally, we fit it with our train dataset and our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_spam_classifier = MultinomialNB()\n",
    "base_spam_classifier.fit(spam_features, train_data.spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the test set, we calculate the confusion matrix (know as an error matrix) using ${\\it confusion\\_matrix}$ method from sklearn using the test set, and then we plot it.\n",
    "\n",
    "Since ${\\it plot\\_confusion\\_matrix}$ method is not working, we calculate matrix coefficients and them plot it with ${\\it imshow}$ method, from matplotlib. Nevertheless, ${\\it plot\\_confusion\\_matrix}$ method should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[587,   9],\n",
       "       [  8, 224]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vectorizer.transform(test_data.text)\n",
    "base_predicted =  base_spam_classifier.predict(test_features)\n",
    "confusion_matrix(test_data.spam, base_predicted)\n",
    "#plot_confusion_matrix(base_spam_classifier, test_data.text, test_data.spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a12f326a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(confusion_matrix(test_data.spam, base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate ${\\it recall}$ and ${\\it precison}$ scores with sklearn library, as well as the accuracy. We can see that we obtain high values, so it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9794685990338164\n",
      "The recall score is: 0.9655172413793104\n",
      "The precision score is: 0.9613733905579399\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is:' ,accuracy_score(test_data.spam, base_predicted))\n",
    "print('The recall score is:', recall_score(test_data.spam, base_predicted))\n",
    "print('The precision score is:', precision_score(test_data.spam, base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we proceed to calculate ROC curve and AUC score with sklearn library. In order to do that, we calculate estimated probabilities with ${\\it preditc\\_proba}$ method. First of all, we calculate TPR and FPR scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR = [0.    0.591 0.616 0.616 0.862 0.862 0.866 0.866 0.905 0.905 0.935 0.935\n",
      " 0.991 0.991 0.996 0.996 1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.   ]\n",
      "FPR = [0.    0.007 0.007 0.008 0.008 0.01  0.01  0.012 0.012 0.013 0.013 0.015\n",
      " 0.015 0.018 0.018 0.022 0.022 0.06  0.064 0.102 0.106 0.107 0.111 0.159\n",
      " 0.163 0.195 0.198 0.227 0.23  0.27  0.277 0.393 0.401 0.565 0.569 0.574\n",
      " 0.577 0.671 0.674 0.706 0.71  0.772 0.775 0.948 1.   ]\n"
     ]
    }
   ],
   "source": [
    "base_proba = base_spam_classifier.predict_proba(test_features)\n",
    "\n",
    "fpr, tpr, ths = roc_curve(test_data.spam, base_proba[:,1])\n",
    "\n",
    "print('TPR =', np.round(tpr, 3))\n",
    "print('FPR =', np.round(fpr, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate that AUC score and prot ROC curve. We remark that red line, with between points $[0, 0]$ and $[1, 1]$ is randomly classified (this would be the standart classifier with $TPR, FPR = [0, 1]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9938599282573478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a12f36a58>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('AUC score:', roc_auc_score(test_data.spam, base_proba[:,1]))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], ':r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get percentage of valid mails classified as spam we have to substract test data to predicted labels ($prediction - data$), so we get $+1$ where it is valid mail classified as spam, and $-1$ where it is spam classified as valid mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5100671140939597"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_valid_mails = np.count_nonzero(np.array(test_data.spam) == 0)\n",
    "np.count_nonzero((base_predicted - np.array(test_data.spam)) == 1) * 100 / N_valid_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have about $1.5\\%$ misclassified valid mails over all valid mails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to count number of $-1$ values using previous method, where it is spam classified as valild mail (ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3445378151260505"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_classified_valid_mails = np.count_nonzero(np.array(base_predicted) == 0)\n",
    "np.count_nonzero((base_predicted - np.array(test_data.spam)) == -1) * 100 / N_classified_valid_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have about $3\\%$ misclassified spam over all predicted as valid mails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we calculate position of ten most and least probable words using ${\\it argsort}$ method from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "most_probable = np.argsort(base_spam_classifier.feature_log_prob_, axis=1)[:,-n-1:-1]\n",
    "least_probable = np.argsort(base_spam_classifier.feature_log_prob_, axis=1)[:,0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define ${\\it word}$ function in order to get words in the vocabulary from those indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word(i):\n",
    "    return vectorizer.get_feature_names()[i]\n",
    "\n",
    "word = np.vectorize(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we calculate the most and least probable words associate with these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_words = word(most_probable)\n",
    "\n",
    "least_words = word(least_probable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display it as dataframes. This is for most probable words. Each time we run the program we obtain nearly the same words, because this words are common instead we have different test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>you</td>\n",
       "      <td>of</td>\n",
       "      <td>on</td>\n",
       "      <td>enron</td>\n",
       "      <td>subject</td>\n",
       "      <td>hou</td>\n",
       "      <td>for</td>\n",
       "      <td>and</td>\n",
       "      <td>ect</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>subject</td>\n",
       "      <td>your</td>\n",
       "      <td>this</td>\n",
       "      <td>is</td>\n",
       "      <td>for</td>\n",
       "      <td>you</td>\n",
       "      <td>in</td>\n",
       "      <td>of</td>\n",
       "      <td>and</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1     2     3      4        5    6    7    8    9  10\n",
       "ham       you    of    on  enron  subject  hou  for  and  ect  to\n",
       "spam  subject  your  this     is      for  you   in   of  and  to"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(most_words, index=['ham', 'spam'], columns=range(1, n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we display least probable words. Each time we run the program we obtain different words, because we have different test data and this words are not common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>iezgm</td>\n",
       "      <td>loaders</td>\n",
       "      <td>loa</td>\n",
       "      <td>lnz</td>\n",
       "      <td>lnventory</td>\n",
       "      <td>lnterest</td>\n",
       "      <td>lnter</td>\n",
       "      <td>lnstant</td>\n",
       "      <td>lnsr</td>\n",
       "      <td>lnpefo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>wst</td>\n",
       "      <td>loses</td>\n",
       "      <td>yeverino</td>\n",
       "      <td>fossesca</td>\n",
       "      <td>seemyw</td>\n",
       "      <td>seelig</td>\n",
       "      <td>fosdick</td>\n",
       "      <td>buckets</td>\n",
       "      <td>buckley</td>\n",
       "      <td>seeger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1        2         3         4          5         6        7  \\\n",
       "ham   iezgm  loaders       loa       lnz  lnventory  lnterest    lnter   \n",
       "spam    wst    loses  yeverino  fossesca     seemyw    seelig  fosdick   \n",
       "\n",
       "            8        9      10  \n",
       "ham   lnstant     lnsr  lnpefo  \n",
       "spam  buckets  buckley  seeger  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(least_words, index=['ham', 'spam'], columns=range(1, n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With os module we obtain all Enron files in data. Then, with a loop, we iterate all this files and calculate their recall and precision scores.\n",
    "\n",
    "With Enron_1 we obtain slightly different values than before because now we're using all data as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Enron_5 has recall: 0.96625 and precision: 0.9408387924630242\n",
      "File Enron_2 has recall: 0.9491545904133423 and precision: 0.9154253405533388\n",
      "File Enron_3 has recall: 0.9700560922405734 and precision: 0.9470555110992561\n",
      "File Enron_4 has recall: 0.9413830230619618 and precision: 0.9270554836420238\n",
      "File Enron_1 has recall: 0.9792475314947224 and precision: 0.9830920914141368\n",
      "File Enron_6 has recall: 0.9530555555555555 and precision: 0.9457197513151602\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('data')\n",
    "\n",
    "for i in files:\n",
    "    data = load_files('data/' + i, encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "    \n",
    "    df = pd.DataFrame({'text': data['data'], 'spam': data['target']})\n",
    "        \n",
    "    test_features_files = vectorizer.transform(df.text)\n",
    "    base_predicted_files =  base_spam_classifier.predict(test_features_files)\n",
    "    \n",
    "    recall = recall_score(df.spam, base_predicted_files, average='macro')\n",
    "    precision =  precision_score(df.spam, base_predicted_files, average='macro')\n",
    "    \n",
    "    print('File', i, 'has recall:', recall , 'and precision:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new folder with ${\\it ham}$ and ${\\it spam}$ subfolders, so we copy there all our data. We have to run it only once.\n",
    "\n",
    "We use a new function to avoid some problems of ${\\it copytree}$ method, from shutil module.\n",
    "\n",
    "We could just store data in previous loop, but this way we have all data toghether, to use it in further calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('all_data')\n",
    "os.mkdir('ham')\n",
    "os.mkdir('spam')\n",
    "\n",
    "source = os.path.abspath(os.getcwd())\n",
    "  \n",
    "dest1 = shutil.move(source + '/ham', source + '/all_data')\n",
    "dest2 = shutil.move(source + '/spam', source + '/all_data') \n",
    "\n",
    "files = os.listdir('data')\n",
    "\n",
    "def copytree(src, dst, symlinks=False, ignore=None):\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "for i in files:\n",
    "    copytree('data/' + i + '/ham', 'all_data/ham')\n",
    "    copytree('data/' + i + '/spam', 'all_data/spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we do that, we can define a new data set and train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    13736\n",
      "0    13234\n",
      "Name: spam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_data = load_files('all_data', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "\n",
    "df = pd.DataFrame({'text': all_data['data'], 'spam': all_data['target']})\n",
    "\n",
    "N_all_data = len(df)\n",
    "N_train_all_data = int(0.8 * N_all_data); N_test_all_data = N_all_data - N_train_all_data\n",
    "\n",
    "train_all_data, test_all_data = train_test_split(df, train_size=N_train_all_data, test_size=N_test_all_data)\n",
    "\n",
    "print(df.spam.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features = vectorizer.fit_transform(train_all_data.text)\n",
    "base_spam_classifier.fit(spam_features, train_all_data.spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $B_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the test set, we draw the confusion matrix using  plot_confusion_matrix  method from sklearn using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2614,   41],\n",
       "       [  36, 2703]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vectorizer.transform(test_all_data.text)\n",
    "base_predicted =  base_spam_classifier.predict(test_features)\n",
    "confusion_matrix(test_all_data.spam, base_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a12f46710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(confusion_matrix(test_all_data.spam, base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $B_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate  recall  and  precison  scores with sklearn library, as well as the accuracy. We can see that we obtain high values, so it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.985724879495736\n",
      "The recall score is: 0.9868565169769989\n",
      "The precision score is: 0.9850583090379009\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is:' ,accuracy_score(test_all_data.spam, base_predicted))\n",
    "print('The recall score is:', recall_score(test_all_data.spam, base_predicted))\n",
    "print('The precision score is:', precision_score(test_all_data.spam, base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $B_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we proceed to calculate ROC curve and AUC score with sklearn library. In order to do that, we calculate estimated probabilities with  preditc_proba  method. First of all, we calculate TPR and FPR scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR = [0.    0.735 0.736 0.741 0.742 0.746 0.747 0.751 0.752 0.756 0.756 0.758\n",
      " 0.759 0.76  0.761 0.762 0.763 0.764 0.765 0.767 0.768 0.769 0.769 0.77\n",
      " 0.771 0.772 0.773 0.774 0.775 0.777 0.777 0.778 0.781 0.782 0.786 0.787\n",
      " 0.793 0.793 0.794 0.795 0.797 0.798 0.801 0.802 0.803 0.804 0.813 0.814\n",
      " 0.835 0.835 0.857 0.858 0.859 0.86  0.864 0.865 0.875 0.876 0.889 0.889\n",
      " 0.894 0.895 0.9   0.9   0.903 0.905 0.908 0.909 0.913 0.914 0.919 0.92\n",
      " 0.921 0.921 0.93  0.931 0.936 0.936 0.939 0.939 0.942 0.942 0.948 0.948\n",
      " 0.951 0.951 0.954 0.954 0.959 0.96  0.961 0.961 0.964 0.964 0.965 0.965\n",
      " 0.965 0.968 0.968 0.97  0.97  0.97  0.97  0.973 0.974 0.974 0.978 0.978\n",
      " 0.981 0.981 0.982 0.982 0.983 0.983 0.984 0.984 0.985 0.985 0.985 0.985\n",
      " 0.985 0.985 0.987 0.987 0.988 0.99  0.991 0.992 0.993 0.993 0.994 0.994\n",
      " 0.994 0.994 0.995 0.995 0.995 0.995 0.996 0.996 0.996 0.996 0.997 0.997\n",
      " 0.997 0.997 0.997 0.997 0.998 0.998 0.998 0.998 0.998 0.998 0.998 0.998\n",
      " 0.998 0.998 0.999 0.999 0.999 0.999 0.999 0.999 1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
      " 1.   ]\n",
      "FPR = [0.      0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452\n",
      " 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452\n",
      " 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452 0.00452\n",
      " 0.00452 0.00452 0.00452 0.0049  0.0049  0.0049  0.0049  0.0049  0.0049\n",
      " 0.0049  0.0049  0.0049  0.0049  0.0049  0.0049  0.0049  0.0049  0.0049\n",
      " 0.0049  0.0049  0.0049  0.0049  0.00527 0.00527 0.00527 0.00527 0.00527\n",
      " 0.00527 0.00527 0.00527 0.00527 0.00527 0.00565 0.00565 0.00565 0.00565\n",
      " 0.00603 0.00603 0.00603 0.00603 0.00603 0.00603 0.00603 0.00603 0.00603\n",
      " 0.00603 0.0064  0.0064  0.0064  0.0064  0.00716 0.00716 0.00716 0.00716\n",
      " 0.00716 0.00716 0.00753 0.00753 0.00791 0.00791 0.00829 0.00829 0.00829\n",
      " 0.00829 0.00866 0.00866 0.00904 0.00904 0.00904 0.00942 0.00942 0.00979\n",
      " 0.00979 0.01017 0.01017 0.01055 0.01055 0.01055 0.01092 0.01092 0.0113\n",
      " 0.0113  0.01168 0.01168 0.01205 0.01205 0.01318 0.01318 0.01356 0.01356\n",
      " 0.01469 0.01469 0.01507 0.01507 0.01544 0.01544 0.01582 0.01582 0.01582\n",
      " 0.01582 0.01582 0.01582 0.01695 0.01695 0.01733 0.01733 0.01808 0.01808\n",
      " 0.01846 0.01846 0.01921 0.01921 0.01996 0.01996 0.02034 0.02034 0.02298\n",
      " 0.02298 0.02486 0.02486 0.02674 0.02674 0.03729 0.03729 0.0403  0.04105\n",
      " 0.04256 0.04331 0.05047 0.05122 0.06215 0.06215 0.08286 0.08286 0.09002\n",
      " 0.09002 0.14878 0.14878 0.17627 0.17702 0.17853 0.17853 0.19586 0.19661\n",
      " 0.20038 0.20151 0.22072 0.22147 0.23352 0.23427 0.28964 0.2904  0.33107\n",
      " 0.33183 0.33936 0.34049 0.35932 0.36008 0.40188 0.40264 0.41168 0.41318\n",
      " 0.41959 0.42072 0.42599 0.42674 0.42825 0.42976 0.43126 0.43277 0.46817\n",
      " 0.46893 0.52015 0.5209  0.53974 0.54049 0.54802 0.54878 0.59096 0.59171\n",
      " 0.62561 0.62637 0.6806  0.68136 0.68927 0.69002 0.75367 0.75443 0.7774\n",
      " 0.77815 0.87269 0.87382 0.88023 0.88098 0.92429 0.92505 0.93333 0.93409\n",
      " 0.94689 0.94765 0.9548  1.     ]\n"
     ]
    }
   ],
   "source": [
    "base_proba = base_spam_classifier.predict_proba(test_features)\n",
    "\n",
    "fpr, tpr, ths = roc_curve(test_all_data.spam, base_proba[:,1])\n",
    "\n",
    "print('TPR =', np.round(tpr, 3))\n",
    "print('FPR =', np.round(fpr, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate that AUC score and plot ROC curve. We remark that red line, between points [0,0] and [1,1], is randomly classified (this would be the standart classifier with $TPR,FPR=[0,1]$).\n",
    "\n",
    "We obtain a similar than before AUC score (maybe a bit lower sometimes, it depends on train-test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9964118758891068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1649d2e8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('AUC score:', roc_auc_score(test_all_data.spam, base_proba[:,1]))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], ':r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $B_4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get percentage of valid mails classified as spam we have to substract test data to predicted labels ($predictio−data$), so we get  +1  where it is valid mail classified as spam, and  −1  where it is spam classified as valid mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5442561205273069"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_valid_mails =  np.count_nonzero(np.array(test_all_data.spam) == 0)\n",
    "np.count_nonzero((base_predicted - np.array(test_all_data.spam)) == 1) * 100 / N_valid_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have about  1.5%  misclassified valid mails over all valid mails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $B_5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to count number of  −1  values using previous method, where it is spam classified as valild mail (ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3584905660377358"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_classified_valid_mails = np.count_nonzero(np.array(base_predicted) == 0)\n",
    "np.count_nonzero((base_predicted - np.array(test_all_data.spam)) == -1) * 100 / N_classified_valid_mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have about  1%  misclassified spam over all classified as valid mails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of misclassified ham mails is equal to $FPR$, where: \n",
    "\n",
    "\\begin{equation}\n",
    "    FPR = \\frac{FP}{FP + TN}\n",
    "\\end{equation}\n",
    "\n",
    "Then, we use $ROC$ curve to calculate value of threeshold ($THS$) at this $FPR$ value. Then, we calculate confusion matrix at this threeshold, so we can calculate false omission rate ($FOR$), which is the percentage of spam (classified as ham) in our inbox, and where:\n",
    "\n",
    "\\begin{equation}\n",
    "    FOR = \\frac{FN}{FN + TN}\n",
    "\\end{equation}\n",
    "\n",
    "We want $FPR = 0.5\\%$, so we look to our values in $ROC$ curve and we do the average between firs and last value of $THS$ rounded equal to $0.005$ (we're doing an interpolation, wich should be really accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THS = 0.9999999240867994\n"
     ]
    }
   ],
   "source": [
    "THS = (ths[np.where(np.round(fpr, 3) == 0.005)][0] + ths[np.where(np.round(fpr, 3) == 0.005)][-1]) / 2\n",
    "print('THS =', THS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we obtain our $FOR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR = 0.10746873943899966\n"
     ]
    }
   ],
   "source": [
    "[[TN, FP], [FN, TP]] = confusion_matrix(test_all_data.spam, base_proba[:, 1]>THS)\n",
    "print('FOR =', FN / (FN + TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the percetage of spam in our inbox is around $10\\%$.\n",
    "\n",
    "We could use widgets form matplotlib library to get this value in ROC curve. But, since we're obtaning different values in the curve each time we iterate it, it's not usefull.\n",
    "\n",
    "What's more, around $FPR = 0.5\\%$ the curve behaves as a linear function, so interpolation should be a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
